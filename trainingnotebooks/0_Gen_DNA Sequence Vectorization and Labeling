{"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c94f41c","executionInfo":{"status":"ok","timestamp":1750843804092,"user_tz":-480,"elapsed":16538,"user":{"displayName":"E Lim (Ravenblack)","userId":"17834193743273807131"}},"outputId":"5a869571-c85f-43c2-93d1-3238c2ee3324"},"source":["!pip install biopython"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biopython\n","  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n","Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython\n","Successfully installed biopython-1.85\n"]}]},{"cell_type":"code","source":["# Import Libraries\n","\n","import os\n","from Bio import SeqIO\n","import numpy as np\n","import pandas as pd\n","import re"],"metadata":{"id":"xFHg3gopV4fQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define Encoding"],"metadata":{"id":"0-SPmGxCWIXh"}},{"cell_type":"code","source":["\n","# --- 2. Define the Nucleotide One-Hot Encoding Mapping ---\n","# Each nucleotide is represented as a 4-element vector.\n","# N (any base) or other unexpected characters will be encoded as all zeros.\n","NUCLEOTIDE_MAP = {\n","    'A': [1, 0, 0, 0],\n","    'C': [0, 1, 0, 0],\n","    'G': [0, 0, 1, 0],\n","    'T': [0, 0, 0, 1],\n","    'N': [0, 0, 0, 0] # Represent 'N' as all zeros\n","}\n","# Default encoding for any character not in NUCLEOTIDE_MAP (e.g., 'R', 'Y', etc.)\n","UNKNOWN_NUCLEOTIDE_ENCODING = [0, 0, 0, 0]"],"metadata":{"id":"C-B7VlWjWAjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Functions for parsing files"],"metadata":{"id":"dKH0x5qLWEkb"}},{"cell_type":"code","source":["# --- 1. Helper Functions for Parsing Files ---\n","\n","def parse_fasta(filepath):\n","    \"\"\"\n","    Parses a FASTA file and extracts sequence IDs and their corresponding DNA sequences.\n","\n","    Args:\n","        filepath (str): Path to the FASTA file.\n","\n","    Returns:\n","        dict: A dictionary where keys are sequence IDs (e.g., 'NC_026433.1')\n","              and values are the DNA sequence strings.\n","    \"\"\"\n","    sequences = {}\n","    try:\n","        with open(filepath, \"r\") as f:\n","            for record in SeqIO.parse(f, \"fasta\"):\n","                # Use the full record ID as the key\n","                sequences[record.id.strip()] = str(record.seq).upper() # Convert to uppercase for consistent encoding\n","    except FileNotFoundError:\n","        print(f\"Error: FASTA file not found at {filepath}\")\n","    except Exception as e:\n","        print(f\"Error parsing FASTA file {filepath}: {e}\")\n","    return sequences\n","\n","# Removing parse_acc_file as it's no longer needed\n","\n","# --- 2. Function for One-Hot Encoding ---\n","\n","def one_hot_encode_sequence(sequence):\n","    \"\"\"\n","    Converts a DNA sequence string into a one-hot encoded numerical representation.\n","\n","    Args:\n","        sequence (str): The DNA sequence string (e.g., \"ATGC\").\n","\n","    Returns:\n","        list of lists: A list where each inner list is the one-hot encoding\n","                       for a nucleotide (e.g., [[1,0,0,0], [0,0,0,1], ...]).\n","                       Unknown characters are encoded as all zeros.\n","    \"\"\"\n","    encoded_sequence = []\n","    for nucleotide in sequence:\n","        encoded_sequence.append(NUCLEOTIDE_MAP.get(nucleotide.upper(), UNKNOWN_NUCLEOTIDE_ENCODING))\n","    return encoded_sequence\n","\n","# --- 3. Main Vectorization and Labeling Function ---\n","\n","def vectorize_dna_data(fasta_files_dir):\n","    \"\"\"\n","    Vectorizes DNA sequences from FASTA files and labels them by source filename.\n","    Pads them to a uniform length.\n","\n","    Args:\n","        fasta_files_dir (str): Directory containing FASTA files (e.g., 'Virustype1.fasta').\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - pandas.DataFrame: A DataFrame with 'Sequence_ID', 'Source_File', and 'Vectorized_Sequence' columns.\n","                                'Vectorized_Sequence' contains the raw (unpadded) vectorized sequence lists.\n","            - numpy.ndarray: A 3D NumPy array of all padded and vectorized sequences,\n","                             ready for CNN input (shape: num_sequences x max_length x 4).\n","            - numpy.ndarray: A 1D NumPy array of corresponding source file labels (strings).\n","            - numpy.ndarray: A 1D NumPy array of corresponding sequence IDs (strings).\n","    \"\"\"\n","    all_sequences_data = [] # To store (sequence_id, source_file, raw_vectorized_sequence)\n","\n","    # Get list of FASTA files\n","    fasta_files = [f for f in os.listdir(fasta_files_dir) if f.endswith('.fasta')]\n","\n","    if not fasta_files:\n","        print(f\"No FASTA files found in {fasta_files_dir}. Please check the directory path and file names.\")\n","        return pd.DataFrame(), np.array([]), np.array([]), np.array([])\n","\n","    print(f\"Found {len(fasta_files)} FASTA files. Processing...\")\n","    for fasta_filename in fasta_files:\n","        fasta_filepath = os.path.join(fasta_files_dir, fasta_filename)\n","\n","        print(f\"Processing {fasta_filename}...\")\n","\n","        fasta_sequences = parse_fasta(fasta_filepath)\n","\n","        # Process all sequences found in the FASTA file\n","        for seq_id, dna_sequence in fasta_sequences.items():\n","            vectorized_seq = one_hot_encode_sequence(dna_sequence)\n","            # Use the filename without the extension as the label\n","            source_label = os.path.splitext(fasta_filename)[0]\n","            all_sequences_data.append({\n","                'Sequence_ID': seq_id,\n","                'Source_File': source_label, # Use filename without extension as a label\n","                'Vectorized_Sequence': vectorized_seq # Store as list of lists (pre-padded)\n","            })\n","\n","\n","    if not all_sequences_data:\n","        print(\"No sequences processed. Exiting.\")\n","        return pd.DataFrame(), np.array([]), np.array([]), np.array([])\n","\n","    # Create a DataFrame from the collected data\n","    df = pd.DataFrame(all_sequences_data)\n","\n","    # Determine the maximum sequence length for padding\n","    # Get the length of the *vectorized* sequence (number of nucleotides)\n","    max_seq_length = df['Vectorized_Sequence'].apply(len).max()\n","    print(f\"\\nMaximum sequence length found: {max_seq_length} nucleotides.\")\n","    print(\"Padding all sequences to this length...\")\n","\n","    # Pad vectorized sequences\n","    padded_vectorized_sequences = []\n","    for _, row in df.iterrows():\n","        seq = row['Vectorized_Sequence']\n","        # Pad with UNKNOWN_NUCLEOTIDE_ENCODING ([0,0,0,0])\n","        padded_seq = seq + [UNKNOWN_NUCLEOTIDE_ENCODING] * (max_seq_length - len(seq))\n","        padded_vectorized_sequences.append(padded_seq)\n","\n","    # Convert to a 3D NumPy array for CNN input\n","    # Shape: (number of sequences, max_seq_length, 4)\n","    cnn_input_sequences = np.array(padded_vectorized_sequences, dtype=np.float32)\n","\n","    # Prepare labels and sequence IDs as NumPy arrays\n","    labels = df['Source_File'].to_numpy()\n","    sequence_ids = df['Sequence_ID'].to_numpy()\n","\n","    print(\"\\nVectorization and labeling complete.\")\n","    print(f\"Total sequences processed: {len(df)}\")\n","    print(f\"Shape of CNN input array: {cnn_input_sequences.shape}\") # (num_samples, seq_length, 4)\n","    print(f\"Labels unique values: {np.unique(labels)}\")\n","\n","    df_list = df.drop('Vectorized_Sequence', axis=1)\n","\n","    return df_list, cnn_input_sequences, labels, sequence_ids"],"outputs":[],"execution_count":null,"metadata":{"id":"xNqClKck9S9Y"}},{"cell_type":"markdown","source":["### Run the functions"],"metadata":{"id":"BwijoDuW92Gw"}},{"cell_type":"code","source":["# FOR COLAB NOTEBOOKS\n","\n","# Code for colab to mount the drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9S_U_cs9pnm","executionInfo":{"status":"ok","timestamp":1750843843838,"user_tz":-480,"elapsed":21050,"user":{"displayName":"E Lim (Ravenblack)","userId":"17834193743273807131"}},"outputId":"43c47002-8ce5-41e3-fbc0-299880c00ab8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","# Define the path to your zip file and the target directory for extraction\n","data_directory = '/content/drive/MyDrive/Colab Notebooks/VectorizeDNA/data_flavi'"],"metadata":{"id":"15D-frsh-Wsw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- 6. Example Usage ---\n","\n","# For Google Colab, if you upload files, they might be in '/content/'\n","# or you might mount Google Drive.\n","\n","# Run the main function\n","df_result, cnn_sequences, cnn_labels, cnn_accessions = vectorize_dna_data(\n","    fasta_files_dir=data_directory\n",")\n","\n","# Display a sample of the results\n","print(\"\\n--- Sample of Processed Data (DataFrame) ---\")\n","print(df_result.head())\n","\n","print(\"\\n--- Example of first padded vectorized sequence (first 5 nucleotides) ---\")\n","if len(cnn_sequences) > 0:\n","    print(cnn_sequences[0][:5])\n","else:\n","    print(\"No sequences to display.\")\n","\n","print(\"\\n--- Example of first 5 labels ---\")\n","print(cnn_labels[:5])\n","\n","print(\"\\n--- Example of first 5 accession numbers ---\")\n","print(cnn_accessions[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85p4Oin89oaR","executionInfo":{"status":"ok","timestamp":1750847181844,"user_tz":-480,"elapsed":84220,"user":{"displayName":"E Lim (Ravenblack)","userId":"17834193743273807131"}},"outputId":"0c0df1be-d92d-4feb-9a29-82966ffe1ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7 FASTA files. Processing...\n","Processing Dengue1.fasta...\n","Processing Dengue2.fasta...\n","Processing Dengue3.fasta...\n","Processing Dengue4.fasta...\n","Processing Zika.fasta...\n","Processing JapaneseEncephalitisVirus.fasta...\n","Processing WestNileVirus.fasta...\n","\n","Maximum sequence length found: 11520 nucleotides.\n","Padding all sequences to this length...\n","\n","Vectorization and labeling complete.\n","Total sequences processed: 7853\n","Shape of CNN input array: (7853, 11520, 4)\n","Labels unique values: ['Dengue1' 'Dengue2' 'Dengue3' 'Dengue4' 'JapaneseEncephalitisVirus'\n"," 'WestNileVirus' 'Zika']\n","\n","--- Sample of Processed Data (DataFrame) ---\n","   Sequence_ID Source_File\n","0  NC_001477.1     Dengue1\n","1   PV798798.1     Dengue1\n","2   PV789653.1     Dengue1\n","3   PV344258.1     Dengue1\n","4   PV344259.1     Dengue1\n","\n","--- Example of first padded vectorized sequence (first 5 nucleotides) ---\n","[[1. 0. 0. 0.]\n"," [0. 0. 1. 0.]\n"," [0. 0. 0. 1.]\n"," [0. 0. 0. 1.]\n"," [0. 0. 1. 0.]]\n","\n","--- Example of first 5 labels ---\n","['Dengue1' 'Dengue1' 'Dengue1' 'Dengue1' 'Dengue1']\n","\n","--- Example of first 5 accession numbers ---\n","['NC_001477.1' 'PV798798.1' 'PV789653.1' 'PV344258.1' 'PV344259.1']\n"]}]},{"cell_type":"code","source":["# save generated results\n","\n","drive_path = '/content/drive/MyDrive/Colab Notebooks/VectorizeDNA/data_flavi'\n","os.makedirs(drive_path, exist_ok=True) # Create directory if it doesn't exist\n","df_result.to_csv(os.path.join(drive_path, 'processed_dna_data.csv'), index=False)\n","np.save(os.path.join(drive_path, 'cnn_sequences.npy'), cnn_sequences)\n","np.save(os.path.join(drive_path, 'cnn_labels.npy'), cnn_labels)\n","np.save(os.path.join(drive_path, 'cnn_accessions.npy'), cnn_accessions)\n","print(f\"\\nResults saved to Google Drive at {drive_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bv9kDsa0_qIi","executionInfo":{"status":"ok","timestamp":1750847207666,"user_tz":-480,"elapsed":17551,"user":{"displayName":"E Lim (Ravenblack)","userId":"17834193743273807131"}},"outputId":"5dbfafb8-d03f-4b23-b4e2-2eed671cc0c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Results saved to Google Drive at /content/drive/MyDrive/Colab Notebooks/VectorizeDNA/data_flavi\n"]}]},{"cell_type":"code","source":["# Count the number of samples per class\n","classes, counts = np.unique(cnn_labels, return_counts=True)\n","\n","print(\"Number of samples per class:\")\n","for class_name, count in zip(classes, counts):\n","    print(f\"- {class_name}: {count}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trBv0ceNYMpe","executionInfo":{"status":"ok","timestamp":1750847210594,"user_tz":-480,"elapsed":8,"user":{"displayName":"E Lim (Ravenblack)","userId":"17834193743273807131"}},"outputId":"97dbd51e-b3fe-4447-a250-242e65a82d43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples per class:\n","- Dengue1: 1924\n","- Dengue2: 1656\n","- Dengue3: 1020\n","- Dengue4: 256\n","- JapaneseEncephalitisVirus: 538\n","- WestNileVirus: 2089\n","- Zika: 370\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3GxIVGZQ2Qxo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 24/6/2025\n","\n","Padding and strides\n","https://medium.com/@minhazc.engg/padding-and-strides-in-cnn-58dc56493887\n","\n"],"metadata":{"id":"2rcn5pkGl0cm"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}